"""
Kalman Forecaster - Time-Varying Kalman Filter –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
==================================================================

–ú–µ—Ç–æ–¥—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è Œ≤:
- last_beta: –ø–æ—Å–ª–µ–¥–Ω–∏–π Œ≤ –ø–æ—Å—Ç–æ—è–Ω–µ–Ω
- random_walk: random walk —Å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å—é
- linear_trend: –ª–∏–Ω–µ–π–Ω–∞—è —ç–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è
- ar_beta: AR –º–æ–¥–µ–ª—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Œ≤
- damped_trend: –∑–∞—Ç—É—Ö–∞—é—â–∏–π —Ç—Ä–µ–Ω–¥
- bayesian_shrinkage: –±–∞–π–µ—Å–æ–≤—Å–∫–æ–µ —Å–∂–∞—Ç–∏–µ
- adaptive_ensemble: –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å
"""

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib import rcParams
import os
import warnings
import joblib
import yaml

from pykalman import KalmanFilter
from statsmodels.tsa.ar_model import AutoReg
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

warnings.filterwarnings('ignore')


class KalmanForecaster:
    """
    Time-Varying Kalman Filter –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.
    
    –ú–æ–¥–µ–ª—å:
        Observation: y_t = X_t @ Œ≤_t + v_t  (v_t ~ N(0, R))
        State:       Œ≤_t = Œ≤_{t-1} + w_t    (w_t ~ N(0, Q))
    
    Parameters:
    -----------
    config : str or dict
        –ü—É—Ç—å –∫ YAML –∫–æ–Ω—Ñ–∏–≥—É –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    """
    
    AVAILABLE_METHODS = [
        'last_beta', 'random_walk', 'linear_trend',
        'ar_beta', 'damped_trend', 'bayesian_shrinkage', 'adaptive_ensemble'
    ]
    
    def __init__(self, config=None, **kwargs):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        self.config = self._load_config(config, kwargs)
        self._validate_config()
        
        self.kf_results = None
        self.results = {}
        self.metrics = {}
        self.data = None
        self.is_fitted = False
        
        self._set_seed()
        
        os.makedirs(self.config['results_dir'], exist_ok=True)
        os.makedirs(self.config['models_dir'], exist_ok=True)
    
    def _load_config(self, config, kwargs):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        if isinstance(config, str):
            with open(config, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f)
        elif isinstance(config, dict):
            cfg = config.copy()
        else:
            cfg = {}
        
        defaults = {
            'input_file': 'data/input_data.xlsx',
            'date_column': 'dt',
            'target_column': 'Price',
            'features': [],
            'initial_state_covariance': 100.0,
            'observation_covariance': 1.0,
            'transition_covariance': 0.01,
            'em_iterations': 5,
            'forecast_methods': [
                'last_beta', 'random_walk', 'linear_trend',
                'ar_beta', 'damped_trend', 'bayesian_shrinkage', 'adaptive_ensemble'
            ],
            'test_size_ratio': 0.1,
            'random_seed': 42,
            'results_dir': 'results',
            'models_dir': 'saved_models'
        }
        
        for key, value in defaults.items():
            if key not in cfg:
                cfg[key] = kwargs.get(key, value)
        
        return cfg
    
    def _validate_config(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è"""
        for method in self.config['forecast_methods']:
            if method not in self.AVAILABLE_METHODS:
                raise ValueError(f"Unknown method: {method}. Available: {self.AVAILABLE_METHODS}")
    
    def _set_seed(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed"""
        import random
        seed = self.config['random_seed']
        random.seed(seed)
        np.random.seed(seed)
        os.environ['PYTHONHASHSEED'] = str(seed)
    
    def load_data(self, filepath=None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        filepath = filepath or self.config['input_file']
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {filepath}...")
        
        self.data = pd.read_excel(filepath)
        self.data.dropna(inplace=True)
        
        date_col = self.config['date_column']
        if date_col in self.data.columns:
            self.data[date_col] = pd.to_datetime(self.data[date_col])
            self.data[date_col] = self.data[date_col].dt.to_period('M').dt.to_timestamp()
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(self.data)}")
        return self
    
    def prepare_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        date_col = self.config['date_column']
        target_col = self.config['target_column']
        
        if self.config['features']:
            self.feature_cols = self.config['features']
        else:
            self.feature_cols = [col for col in self.data.columns 
                                if col not in [date_col, target_col]]
        
        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ ({len(self.feature_cols)}): {self.feature_cols}")
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ
        self.data_indexed = self.data[[date_col, target_col] + self.feature_cols].set_index(date_col)
        
        return self
    
    def split_data(self):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        n = len(self.data_indexed)
        test_size = int(n * self.config['test_size_ratio'])
        train_size = n - test_size
        
        self.data_train = self.data_indexed.iloc[:train_size]
        self.data_test = self.data_indexed.iloc[train_size:]
        
        target_col = self.config['target_column']
        self.X_train = self.data_train[self.feature_cols].values
        self.y_train = self.data_train[target_col].values
        self.X_test = self.data_test[self.feature_cols].values
        self.y_test = self.data_test[target_col].values
        
        print(f"\n–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
        print(f"  Train: {train_size} ({100*train_size/n:.1f}%)")
        print(f"  Test: {test_size} ({100*test_size/n:.1f}%)")
        
        return self
    
    def _fit_kalman(self):
        """–û–±—É—á–µ–Ω–∏–µ Kalman Filter"""
        target_col = self.config['target_column']
        
        y = self.data_train[target_col].values
        X = self.X_train
        T, k = X.shape
        
        observation_matrices = X.reshape(T, 1, k)
        
        kf = KalmanFilter(
            transition_matrices=np.eye(k),
            observation_matrices=observation_matrices,
            initial_state_mean=np.zeros(k),
            initial_state_covariance=np.eye(k) * self.config['initial_state_covariance'],
            observation_covariance=np.array([[self.config['observation_covariance']]]),
            transition_covariance=np.eye(k) * self.config['transition_covariance']
        )
        
        try:
            kf = kf.em(y, n_iter=self.config['em_iterations'])
        except:
            print("  EM –Ω–µ —Å–æ—à–µ–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
        
        state_means, state_covs = kf.filter(y)
        smoothed_means, smoothed_covs = kf.smooth(y)
        
        self.kf_results = {
            'kalman_filter': kf,
            'betas_filtered': state_means,
            'betas_smoothed': smoothed_means,
            'state_covs_filtered': state_covs,
            'state_covs_smoothed': smoothed_covs
        }
        
        self.betas_train = state_means
        self.y_train_fitted = np.sum(self.X_train * self.betas_train, axis=1)
        
        return self
    
    def _forecast(self, method):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–º"""
        h, k = self.X_test.shape
        kf = self.kf_results['kalman_filter']
        betas_history = self.kf_results['betas_filtered']
        
        beta_cov_forecast = None
        
        if method == 'last_beta':
            beta_forecast = np.tile(betas_history[-1], (h, 1))
            
        elif method == 'random_walk':
            beta_forecast = []
            beta_cov_forecast = []
            current_beta = betas_history[-1]
            current_cov = self.kf_results['state_covs_filtered'][-1]
            
            for t in range(h):
                next_beta = kf.transition_matrices @ current_beta
                next_cov = (kf.transition_matrices @ current_cov @ 
                           kf.transition_matrices.T + kf.transition_covariance)
                beta_forecast.append(next_beta)
                beta_cov_forecast.append(next_cov)
                current_beta, current_cov = next_beta, next_cov
            
            beta_forecast = np.array(beta_forecast)
            beta_cov_forecast = np.array(beta_cov_forecast)
            
        elif method == 'linear_trend':
            N = min(20, len(betas_history))
            beta_recent = betas_history[-N:]
            t_hist = np.arange(N)
            t_fut = np.arange(N, N + h)
            
            beta_forecast = []
            for i in range(k):
                coeffs = np.polyfit(t_hist, beta_recent[:, i], deg=1)
                beta_forecast.append(np.polyval(coeffs, t_fut))
            beta_forecast = np.array(beta_forecast).T
            
        elif method == 'ar_beta':
            beta_forecast = []
            for i in range(k):
                series = betas_history[:, i]
                try:
                    best_aic, best_model = np.inf, None
                    for p in range(1, min(6, len(series)//3)):
                        try:
                            model = AutoReg(series, lags=p, trend='c').fit()
                            if model.aic < best_aic:
                                best_aic, best_model = model.aic, model
                        except:
                            continue
                    if best_model:
                        beta_forecast.append(best_model.forecast(steps=h))
                    else:
                        beta_forecast.append(np.repeat(series[-1], h))
                except:
                    beta_forecast.append(np.repeat(series[-1], h))
            beta_forecast = np.array(beta_forecast).T
            
        elif method == 'damped_trend':
            N = min(20, len(betas_history))
            beta_recent = betas_history[-N:]
            damping = 0.95
            
            beta_forecast = []
            for i in range(k):
                t_hist = np.arange(N)
                coeffs = np.polyfit(t_hist, beta_recent[:, i], deg=1)
                slope = coeffs[0]
                last = beta_recent[-1, i]
                hist_mean = np.mean(betas_history[:, i])
                
                forecast_i = []
                for t in range(1, h + 1):
                    trend = slope * (1 - damping**t) / (1 - damping)
                    reversion = (hist_mean - last) * (1 - damping**t)
                    forecast_i.append(last + trend * 0.5 + reversion * 0.3)
                beta_forecast.append(forecast_i)
            beta_forecast = np.array(beta_forecast).T
            
        elif method == 'bayesian_shrinkage':
            N = min(30, len(betas_history))
            beta_recent = betas_history[-N:]
            
            beta_forecast = []
            for i in range(k):
                hist_mean = np.mean(betas_history[:, i])
                hist_std = np.std(betas_history[:, i])
                t_hist = np.arange(N)
                coeffs = np.polyfit(t_hist, beta_recent[:, i], deg=1)
                last = betas_history[-1, i]
                
                forecast_i = []
                for t in range(h):
                    if t == 0:
                        beta_t = last
                    else:
                        trend = np.polyval(coeffs, N + t)
                        shrink = min(0.9, 0.3 + 0.02 * t)
                        beta_t = shrink * hist_mean + (1 - shrink) * trend
                        beta_t = np.clip(beta_t, hist_mean - 3*hist_std, hist_mean + 3*hist_std)
                    forecast_i.append(beta_t)
                beta_forecast.append(forecast_i)
            beta_forecast = np.array(beta_forecast).T
            
        elif method == 'adaptive_ensemble':
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞–Ω—Å–∞–º–±–ª—è
            last = np.tile(betas_history[-1], (h, 1))
            
            # AR
            ar_forecast = []
            for i in range(k):
                try:
                    model = AutoReg(betas_history[:, i], lags=min(3, len(betas_history)//4), trend='c').fit()
                    ar_forecast.append(model.forecast(steps=h))
                except:
                    ar_forecast.append(np.repeat(betas_history[-1, i], h))
            ar_forecast = np.array(ar_forecast).T
            
            # Damped
            N = min(20, len(betas_history))
            damped_forecast = []
            for i in range(k):
                t = np.arange(N)
                coeffs = np.polyfit(t, betas_history[-N:, i], deg=1)
                slope = coeffs[0]
                last_val = betas_history[-1, i]
                hist_mean = np.mean(betas_history[:, i])
                
                forecast_i = []
                for s in range(1, h + 1):
                    d = 0.95**s
                    forecast_i.append(last_val + slope * s * d * 0.5 + (hist_mean - last_val) * (1 - d) * 0.3)
                damped_forecast.append(forecast_i)
            damped_forecast = np.array(damped_forecast).T
            
            # –í–µ—Å–∞ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            beta_forecast = []
            for i in range(k):
                vol = np.std(betas_history[-20:, i]) / (np.abs(np.mean(betas_history[:, i])) + 1e-6)
                if vol < 0.2:
                    w = [0.2, 0.5, 0.3]
                elif vol < 0.5:
                    w = [0.3, 0.4, 0.3]
                else:
                    w = [0.5, 0.3, 0.2]
                beta_i = w[0] * last[:, i] + w[1] * ar_forecast[:, i] + w[2] * damped_forecast[:, i]
                beta_forecast.append(beta_i)
            beta_forecast = np.array(beta_forecast).T
        
        else:
            raise ValueError(f"Unknown method: {method}")
        
        y_pred = np.sum(self.X_test * beta_forecast, axis=1)
        
        result = {
            'y_pred': y_pred,
            'beta_forecast': beta_forecast,
            'method': method
        }
        
        if method == 'random_walk' and beta_cov_forecast is not None:
            y_std = []
            for t in range(h):
                var_y = (self.X_test[t]**2 @ np.diag(beta_cov_forecast[t]) + 
                        kf.observation_covariance[0, 0])
                y_std.append(np.sqrt(var_y))
            result['y_std'] = np.array(y_std)
            result['beta_cov_forecast'] = beta_cov_forecast
        
        return result
    
    def fit(self, data_path=None):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        self.load_data(data_path)
        self.prepare_data()
        self.split_data()
        
        print("\n" + "="*60)
        print("–û–ë–£–ß–ï–ù–ò–ï TIME-VARYING KALMAN FILTER")
        print("="*60)
        
        self._fit_kalman()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ train
        train_mae = mean_absolute_error(self.y_train, self.y_train_fitted)
        train_mape = np.mean(np.abs((self.y_train - self.y_train_fitted) / self.y_train)) * 100
        print(f"\n–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ Train:")
        print(f"  MAE: {train_mae:.3f}")
        print(f"  MAPE: {train_mape:.2f}%")
        
        # –¢–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏
        spread = self.y_train - self.y_train_fitted
        adf = adfuller(spread)
        print(f"\n–¢–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞: p-value = {adf[1]:.4f}")
        
        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
        print("\n–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞–º–∏:")
        for method in self.config['forecast_methods']:
            print(f"  - {method}")
            result = self._forecast(method)
            self.results[method] = result
            
            self.metrics[method] = {
                'mae': mean_absolute_error(self.y_test, result['y_pred']),
                'rmse': np.sqrt(mean_squared_error(self.y_test, result['y_pred'])),
                'mape': np.mean(np.abs((self.y_test - result['y_pred']) / self.y_test)) * 100,
                'r2': r2_score(self.y_test, result['y_pred'])
            }
        
        self.is_fitted = True
        self.best_method = min(self.metrics, key=lambda m: self.metrics[m]['mae'])
        print(f"\nüèÜ –õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {self.best_method} (MAE = {self.metrics[self.best_method]['mae']:.4f})")
        
        return self
    
    def predict(self, X, method=None):
        """–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        method = method or self.best_method
        # –ó–¥–µ—Å—å –Ω—É–∂–Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        raise NotImplementedError("Use fit() for new data")
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        results_dir = self.config['results_dir']
        models_dir = self.config['models_dir']
        
        print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        metrics_df = pd.DataFrame(self.metrics).T
        metrics_df.index.name = 'Method'
        metrics_df = metrics_df.sort_values('mae')
        metrics_df.to_excel(os.path.join(results_dir, 'kalman_metrics.xlsx'))
        
        # –ü—Ä–æ–≥–Ω–æ–∑—ã
        preds_df = pd.DataFrame({
            'Date': self.data_test.index,
            'Actual': self.y_test
        })
        for method, res in self.results.items():
            preds_df[f'{method}_pred'] = res['y_pred']
        preds_df.to_excel(os.path.join(results_dir, 'kalman_predictions.xlsx'), index=False)
        
        # Betas
        betas_df = pd.DataFrame(self.betas_train, index=self.data_train.index, columns=self.feature_cols)
        betas_df.to_excel(os.path.join(results_dir, 'kalman_betas_train.xlsx'))
        
        # –ú–æ–¥–µ–ª—å
        joblib.dump({
            'kf_results': self.kf_results,
            'feature_cols': self.feature_cols,
            'best_method': self.best_method,
            'config': self.config
        }, os.path.join(models_dir, 'kalman_model.pkl'))
        
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results_dir}")
        print(f"  –ú–æ–¥–µ–ª–∏: {models_dir}")
        
        return self
    
    def plot_results(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è"""
        results_dir = self.config['results_dir']
        
        colors = {
            'last_beta': 'red', 'random_walk': 'green', 'linear_trend': 'purple',
            'ar_beta': 'cyan', 'damped_trend': 'magenta',
            'bayesian_shrinkage': 'brown', 'adaptive_ensemble': 'olive'
        }
        
        # 1. –í—Å–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
        plt.figure(figsize=(14, 7))
        plt.plot(self.data_train.index, self.y_train, 'k-', label='Train', alpha=0.7)
        plt.plot(self.data_train.index, self.y_train_fitted, 'orange', ls='--', label='Fitted', alpha=0.7)
        plt.plot(self.data_test.index, self.y_test, 'b-', label='Test (—Ñ–∞–∫—Ç)', linewidth=2)
        
        for method, res in self.results.items():
            lw = 2.5 if method == self.best_method else 1.5
            plt.plot(self.data_test.index, res['y_pred'], 
                    label=f"{method} (MAE={self.metrics[method]['mae']:.1f})",
                    color=colors.get(method, 'gray'), linewidth=lw)
        
        plt.axvline(self.data_train.index[-1], color='gray', ls=':', lw=2)
        plt.title('Kalman Filter: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤', fontsize=14)
        plt.legend(fontsize=9, ncol=2)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, 'kalman_all_forecasts.png'), dpi=150)
        plt.close()
        
        # 2. –≠–≤–æ–ª—é—Ü–∏—è Œ≤
        n_feat = len(self.feature_cols)
        fig, axes = plt.subplots(n_feat, 1, figsize=(14, 3*n_feat), sharex=True)
        if n_feat == 1:
            axes = [axes]
        
        for i, col in enumerate(self.feature_cols):
            ax = axes[i]
            ax.plot(self.data_train.index, self.betas_train[:, i], label=f'Œ≤({col})', lw=2)
            ax.axhline(0, color='gray', ls='--', alpha=0.5)
            ax.set_ylabel(f'Œ≤({col})')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        axes[-1].set_xlabel('–î–∞—Ç–∞')
        fig.suptitle('–≠–≤–æ–ª—é—Ü–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ Œ≤(t)', fontsize=14)
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, 'kalman_beta_evolution.png'), dpi=150)
        plt.close()
        
        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        methods = list(self.metrics.keys())
        
        for ax, metric in zip(axes, ['mae', 'mape', 'r2']):
            values = [self.metrics[m][metric] for m in methods]
            bars = ax.bar(methods, values, color=[colors.get(m, 'gray') for m in methods], alpha=0.7)
            best_idx = methods.index(self.best_method)
            bars[best_idx].set_alpha(1.0)
            ax.set_xticklabels(methods, rotation=45, ha='right')
            ax.set_title(metric.upper())
            ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, 'kalman_metrics_comparison.png'), dpi=150)
        plt.close()
        
        print(f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_dir}")
        return self
    
    def summary(self):
        """–ò—Ç–æ–≥–∏"""
        print("\n" + "="*60)
        print("–ò–¢–û–ì–ò KALMAN FORECASTING")
        print("="*60)
        
        print(f"\n{'Method':<25} {'MAE':<10} {'RMSE':<10} {'MAPE':<10} {'R¬≤':<10}")
        print("-"*65)
        
        for method, m in sorted(self.metrics.items(), key=lambda x: x[1]['mae']):
            marker = '‚òÖ' if method == self.best_method else ' '
            print(f"{marker}{method:<24} {m['mae']:<10.3f} {m['rmse']:<10.3f} "
                  f"{m['mape']:<10.2f} {m['r2']:<10.4f}")
        
        print("-"*65)
        print(f"\nüèÜ –õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {self.best_method}")
        print(f"   MAE: {self.metrics[self.best_method]['mae']:.3f}")
        
        return self
